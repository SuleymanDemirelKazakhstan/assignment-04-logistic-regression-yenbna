from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, recall_score

# Combine the processed text for vectorization
all_texts = pd.concat([disaster_tweets_df['processed_text'], normal_tweets_df['processed_text']])
all_labels = [1] * len(disaster_tweets_df) + [0] * len(normal_tweets_df)  # 1 for disaster, 0 for normal

# Vectorize the text
vectorizer = CountVectorizer(max_features=1000) 
X = vectorizer.fit_transform(all_texts)
y = all_labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Logistic Regression model
model = LogisticRegression(max_iter=1000) 
model.fit(X_train, y_train)

# Predict on the testing set
predictions = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, predictions)
f1 = f1_score(y_test, predictions, average='weighted')  # Use 'weighted' for imbalanced classes
recall = recall_score(y_test, predictions, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Recall: {recall:.4f}")
